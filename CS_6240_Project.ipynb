{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKOg3DmZmztt"
      },
      "source": [
        "### Install PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9dwlvw70mV2U"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmmSKICjmgTt",
        "outputId": "5e918196-2f3e-4c6a-e1b2-8dc3fbe8f542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8MOI6GL1mj9H"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yZJFTHAreen"
      },
      "source": [
        "### Get Kaggle Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psRCN-PXp6a1",
        "outputId": "1e158916-d540-4a2f-f9a5-2ed6a359f7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CVzAJMdDp7sH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"***\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"***\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV9ADfdTqHcy",
        "outputId": "7caa1eb7-a5fa-4ece-b29d-87c28911fdc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading paysim1.zip to /content\n",
            " 99% 176M/178M [00:05<00:00, 38.8MB/s]\n",
            "100% 178M/178M [00:05<00:00, 35.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ealaxi/paysim1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxGCfQ9Lq68S",
        "outputId": "31e7b402-74ca-4835-b61f-a225822150f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  paysim1.zip\n",
            "  inflating: PS_20174392719_1491204439457_log.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip paysim1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q90fIBnHTFM"
      },
      "source": [
        "[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktXItkKTHTbf",
        "outputId": "34701234-f2a4-4ce3-dc69-b6238e74faa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     type     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
            "1       2    1864.28        21249.0        19384.72            0.00   \n",
            "2       3     181.00          181.0            0.00            0.00   \n",
            "3       0     181.00          181.0            0.00        21182.00   \n",
            "4       2   11668.14        41554.0        29885.86            0.00   \n",
            "5       2    7817.71        53860.0        46042.29            0.00   \n",
            "..    ...        ...            ...             ...             ...   \n",
            "96      3  581294.26            0.0            0.00      5195482.15   \n",
            "97      3   11996.58            0.0            0.00        40255.00   \n",
            "98      2    2875.10        15443.0        12567.90            0.00   \n",
            "99      2    8586.98         3763.0            0.00            0.00   \n",
            "100     2     871.75        19869.0        18997.25            0.00   \n",
            "\n",
            "     newbalanceDest  target  isFlaggedFraud  \n",
            "1              0.00       0               0  \n",
            "2              0.00       1               0  \n",
            "3              0.00       1               0  \n",
            "4              0.00       0               0  \n",
            "5              0.00       0               0  \n",
            "..              ...     ...             ...  \n",
            "96      19169204.93       0               0  \n",
            "97             0.00       0               0  \n",
            "98             0.00       0               0  \n",
            "99             0.00       0               0  \n",
            "100            0.00       0               0  \n",
            "\n",
            "[100 rows x 8 columns]\n",
            "Model: Logistic Regression, Result: 1.0\n",
            "Model: Ridge, Result: 0.01927633103490384\n",
            "Model: Lasso, Result: 0.01941460626185431\n",
            "Model: Logistic Regression, Result: 1.0\n",
            "Model: Ridge, Result: 0.01927633103490384\n",
            "Model: Lasso, Result: 0.01941460626185431\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from pyspark.sql.functions import broadcast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BroadcastAndRunModels\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_train = pd.read_csv(\"PS_20174392719_1491204439457_log.csv\", nrows=100)\n",
        "df_train = df_train.rename(columns={'isFraud': 'target'})\n",
        "\n",
        "df_train[\"type\"] = df_train[\"type\"].astype('category')\n",
        "df_train[\"type\"] = df_train[\"type\"].cat.codes\n",
        "\n",
        "columns_to_drop = [\"nameDest\", \"nameOrig\", \"step\"]\n",
        "\n",
        "df_train = df_train.drop(columns_to_drop, inplace=False, axis=1)\n",
        "# print(df_train)\n",
        "\n",
        "# Broadcast the training dataset\n",
        "broadcast_train = spark.sparkContext.broadcast(df_train)\n",
        "\n",
        "# Define the models to run\n",
        "models = [\n",
        "    LogisticRegression(),\n",
        "    Ridge(),\n",
        "    Lasso()\n",
        "]\n",
        "\n",
        "# Define a function to run a model on a partition\n",
        "def run_model_on_partition(rows):\n",
        "    # Get the broadcasted training dataset\n",
        "    train_data = broadcast_train.value\n",
        "\n",
        "    # Convert the partition rows to a Pandas DataFrame\n",
        "    #df_partition = pd.DataFrame(rows, columns=df_features.columns)\n",
        "\n",
        "    # Split the data into features and target\n",
        "    X = train_data.drop('target', axis=1)\n",
        "    y = train_data['target']\n",
        "\n",
        "    # Train and evaluate each model on the partition\n",
        "    results = []\n",
        "    for model in models:\n",
        "        model.fit(X, y)\n",
        "\n",
        "        if isinstance(model, LogisticRegression):\n",
        "            y_pred = model.predict(X)\n",
        "            accuracy = accuracy_score(y, y_pred)\n",
        "            results.append(('Logistic Regression', accuracy))\n",
        "        else:\n",
        "            y_pred = model.predict(X)\n",
        "            mse = mean_squared_error(y, y_pred)\n",
        "            results.append((type(model).__name__, mse))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Create an RDD from the training dataset\n",
        "rdd_train = spark.sparkContext.parallelize(df_train.values.tolist())\n",
        "\n",
        "# Apply the model function on each partition of the RDD\n",
        "results_rdd = rdd_train.mapPartitions(run_model_on_partition)\n",
        "\n",
        "# Collect the results from all partitions\n",
        "results = results_rdd.collect()\n",
        "\n",
        "# Print the results\n",
        "for model_name, result in results:\n",
        "    print(f\"Model: {model_name}, Result: {result}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq7Mp9hc91qK"
      },
      "source": [
        "## Pushing code to repo"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
