{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hHbjZQP3Pnhf",
   "metadata": {
    "id": "hHbjZQP3Pnhf"
   },
   "source": [
    "Install Spark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "OmEpdxR_O9w2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmEpdxR_O9w2",
    "outputId": "d784bb74-5264-4c59-d3d4-67c51d8d6d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/saicharan/Documents/pyworkspace/large-scale-project/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/saicharan/Documents/pyworkspace/large-scale-project/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "F_07wGvVPGId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_07wGvVPGId",
    "outputId": "58fcf0a7-1d48-47ac-f191-ea01e65d000b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q_UxniLsPmFn",
   "metadata": {
    "id": "Q_UxniLsPmFn"
   },
   "source": [
    "Import spark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ID2grE0pO_4l",
   "metadata": {
    "id": "ID2grE0pO_4l"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m spark\u001b[38;5;241m=\u001b[39mSparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m=\u001b[39mspark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/course_project/fraud_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "\n",
    "df=spark.read.csv('/content/drive/MyDrive/course_project/fraud_dataset.csv', inferSchema=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Ar4yDEEyREWc",
   "metadata": {
    "id": "Ar4yDEEyREWc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#limiting the data for experimentation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#check the schema\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#limiting the data for experimentation\n",
    "df = df.limit(1000)\n",
    "#check the schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0612c46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#randomly split test and training data set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train, test\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mrandomSplit([\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.2\u001b[39m], seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m)\n\u001b[1;32m      3\u001b[0m train\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#randomly split test and training data set\n",
    "train, test=df.randomSplit([0.8, 0.2], seed=22)\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"nameDest\", \"nameOrig\", \"step\"]\n",
    "\n",
    "# Drop the specified columns\n",
    "train = train.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9172cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_col = \"type\"\n",
    "output_col = \"type_id\"\n",
    "\n",
    "\n",
    "string_indexer = StringIndexer(inputCol=input_col, outputCol=output_col)\n",
    "train = string_indexer.fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_drop = [\"type\"]\n",
    "train = train.drop(*column_to_drop)\n",
    "train.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
